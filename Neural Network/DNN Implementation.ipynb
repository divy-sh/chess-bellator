{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc5ebe5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bb8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall torch\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from random import randrange\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "def fen_to_features(fen):\n",
    "    piece_to_index = {'r': 0, 'n': 1, 'b': 2, 'q': 3, 'k': 4, 'p': 5,\n",
    "                      'P': 6, 'K': 7, 'Q': 8, 'B': 9, 'N': 10, 'R': 11}\n",
    "\n",
    "    one_hot_board = np.zeros((13, 8, 8), dtype=np.float32)\n",
    "    additional_features = np.zeros(13, dtype=np.float32)\n",
    "    # additional_features = np.zeros(1, dtype=np.float32)\n",
    "\n",
    "    fen_rows = fen.split()[0].split('/')\n",
    "    for row_idx, row in enumerate(fen_rows):\n",
    "        col_idx = 0\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                col_idx += int(char)\n",
    "            elif char in piece_to_index:\n",
    "                piece_idx = piece_to_index[char]\n",
    "                one_hot_board[piece_idx, row_idx, col_idx] = 1\n",
    "                col_idx += 1\n",
    "    turn_index = 12\n",
    "    one_hot_board[turn_index, :, :].fill(1)\n",
    "    if fen.split()[1] == 'b':\n",
    "#         print(f'Reached 1 {fen}')\n",
    "        one_hot_board[turn_index, :, :].fill(0)\n",
    "#         one_hot_board = np.rot90(one_hot_board, k = 2)\n",
    "#     additional_features[0] = 1 if fen[1] == 'w' else 0\n",
    "    additional_features[0:4] = [int(right in fen.split()[2]) for right in ['K', 'Q', 'k', 'q']]\n",
    "    if fen.split()[3] != '-':\n",
    "        en_passant_row = ord(fen.split()[3][0]) - ord('a')\n",
    "        additional_features[5 + en_passant_row] = 1\n",
    "    return np.concatenate([one_hot_board.flatten(), additional_features])\n",
    "\n",
    "class EvaluationDataset(IterableDataset):\n",
    "  def __init__(self, count, mode, split_ratio = 0.8):\n",
    "#     self.dataset = []\n",
    "        self.count = count\n",
    "        self.mode = mode\n",
    "        self.split_ratio = split_ratio\n",
    "        self.train_count = int(self.count * self.split_ratio)\n",
    "        self.validation_count = self.count - self.train_count\n",
    "  def __iter__(self):\n",
    "        with open('lichess_db_eval.jsonl', 'r') as file:\n",
    "            if self.mode == 'train':\n",
    "                limit = self.train_count\n",
    "            else:\n",
    "                for _ in range(self.train_count):\n",
    "                    next(file)\n",
    "                limit = self.validation_count\n",
    "\n",
    "            for _ in range(limit):\n",
    "                line = file.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                yield self.process_json_line(line)\n",
    "\n",
    "  def process_json_line(self, line):\n",
    "        json_object = json.loads(line)\n",
    "        fen = json_object['fen']\n",
    "        pv = json_object.get('evals', [{}])[0].get('pvs', [{}])[0]\n",
    "        evaluation = pv.get('cp', 0) or 0\n",
    "\n",
    "        if 'mate' in pv and pv['mate'] is not None:\n",
    "            evaluation = 50000 if pv['mate'] > 0 else -50000\n",
    "\n",
    "        evaluation = max(min(evaluation, 2000), -2000)\n",
    "        evaluation = evaluation/100\n",
    "        if fen.split()[1] == 'b':\n",
    "            evaluation = evaluation*-1\n",
    "#         if fen:\n",
    "#         print('Reached 2')\n",
    "        fen_encoded = fen_to_features(fen)\n",
    "        return {'fen_encoded': fen_encoded, 'eval': evaluation}\n",
    "\n",
    "#   def __next__(self):\n",
    "#     idx = randrange(self.count)\n",
    "#     return self[idx]\n",
    "  def __len__(self):\n",
    "    return self.train_count if self.mode == 'train' else self.validation_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f675d88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEvaluationModel\u001b[39;00m(pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m845\u001b[39m, layer_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "class EvaluationModel(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=1e-3, batch_size=1024, input_dim=845, layer_count=8):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        layers = [(f\"linear-0\", nn.Linear(input_dim, input_dim)), (f\"relu-0\", nn.ReLU())]\n",
    "        for i in range(1, layer_count - 1):\n",
    "#             input_dim = input_dim//2\n",
    "            layers.append((f\"linear-{i}\", nn.Linear(input_dim, input_dim)))\n",
    "            layers.append((f\"relu-{i}\", nn.ReLU()))\n",
    "        layers.append((f\"linear-{layer_count - 1}\", nn.Linear(input_dim, 1)))\n",
    "        self.seq = nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y_eval = batch['fen_encoded'], batch['eval']\n",
    "        x = x.float()\n",
    "        y_eval = y_eval.float()\n",
    "        output = self(x)\n",
    "        y_hat_eval = output[:, 0]\n",
    "        y_hat_eval = y_hat_eval.squeeze()\n",
    "        y_hat_eval = y_hat_eval.float()\n",
    "#         print(type(y_hat_eval))\n",
    "        eval_loss = F.l1_loss(y_hat_eval, y_eval)\n",
    "        loss = eval_loss\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y_eval = batch['fen_encoded'], batch['eval']\n",
    "        x = x.float()\n",
    "        y_eval = y_eval.float()\n",
    "        output = self(x)\n",
    "        y_hat_eval = output[:, 0]\n",
    "        y_hat_eval = y_hat_eval.squeeze()\n",
    "        y_hat_eval = y_hat_eval.float()\n",
    "#         print(type(y_hat_eval))\n",
    "        eval_loss = F.l1_loss(y_hat_eval, y_eval)\n",
    "        loss = eval_loss\n",
    "        self.log(\"validation_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        # scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "        # return {\n",
    "        #     'optimizer': optimizer,\n",
    "        #     'scheduler': scheduler,\n",
    "        # }\n",
    "\n",
    "    def train_dataloader(self):\n",
    "      # dataset = EvaluationDataset(count=3072000)\n",
    "      dataset = EvaluationDataset(count=5072000, mode='train', split_ratio=0.8)\n",
    "      return DataLoader(dataset, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "      # dataset = EvaluationDataset(count=3072000)\n",
    "#       dataset = EvaluationDataset(count=5072000, mode='validation', split_ratio=0.8)\n",
    "      dataset = EvaluationDataset(count=5072000, mode='validation', split_ratio=0.8)\n",
    "      return DataLoader(dataset, batch_size=self.batch_size, pin_memory=True)\n",
    "\n",
    "configs = [\n",
    "          {\"layer_count\": 6, \"batch_size\": 512},\n",
    "           ]\n",
    "for config in configs:\n",
    "#   print(\"Reached 1\")\n",
    "  version_name = f'{int(time.time())}-batch_size-{config[\"batch_size\"]}-layer_count-{config[\"layer_count\"]}'\n",
    "#   print(\"Reached 2\")\n",
    "  logger = pl.loggers.TensorBoardLogger(\"lightning_logs\", name=\"chessml\", version=version_name)\n",
    "#   print(\"Reached 3\")\n",
    "  early_stop_callback = EarlyStopping(monitor='validation_loss', patience=3, verbose=True, mode='min')\n",
    "#   print(\"Reached 4\")\n",
    "  checkpoint_callback = ModelCheckpoint(monitor='validation_loss', save_top_k=1, mode='min')\n",
    "  lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "#   print(\"Reached 5\")\n",
    "  trainer = pl.Trainer(accelerator='gpu',precision=16,max_epochs=20,callbacks=[early_stop_callback, checkpoint_callback], profiler=\"simple\", logger=logger, log_every_n_steps=10)\n",
    "  model = EvaluationModel(layer_count=config[\"layer_count\"],batch_size=config[\"batch_size\"],learning_rate=1e-3)\n",
    "#   print(\"Reached 6\")\n",
    "  trainer.fit(model)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9022ab15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-15dbe541dedc84d3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-15dbe541dedc84d3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --port 6007 --logdir lightning_logs/\n",
    "# !kill 6004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df54e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Eval 0.07\n",
      "eval 0.05\n",
      "y_eval_hat -0.02\n",
      "FEN r1bqkbnr/1p3ppp/p1n1p3/2pp4/B3P3/2P2N2/PP1P1PPP/RNBQK2R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.84\n",
      "eval 0.48\n",
      "y_eval_hat -0.36\n",
      "FEN r1b1qrk1/ppp2pbp/n2p2p1/3Pp1B1/2P1P1n1/2N2N2/PP2BPPP/R2Q1RK1 b - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 2.41\n",
      "eval 3.16\n",
      "y_eval_hat 0.75\n",
      "FEN rnbqkb1r/pp2p2p/2p2p2/3p2pn/3P3B/4PN2/PPP2PPP/RN1QKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.41\n",
      "eval -0.22\n",
      "y_eval_hat 0.19\n",
      "FEN r1bqkbnr/ppp2ppp/8/4n3/4N3/5N2/PPPP2PP/R1BQKB1R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 180.10\n",
      "eval 200.00\n",
      "y_eval_hat 19.90\n",
      "FEN 8/5k2/6RR/8/3K4/8/8/8 w - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.13\n",
      "eval 0.00\n",
      "y_eval_hat -0.13\n",
      "FEN r1bqk2r/pppnppbp/3p1np1/8/3PP3/3B1N2/PPPN1PPP/R1BQK2R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1169.76\n",
      "eval 1150.00\n",
      "y_eval_hat -19.76\n",
      "FEN 8/2R5/3K4/8/8/3k4/8/8 b - -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 0.37\n",
      "eval -0.21\n",
      "y_eval_hat 0.16\n",
      "FEN rn1qkb1r/pp2pppp/2p2n2/3p1b2/2PP1B2/6P1/PP2PPBP/RN1QK1NR b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.52\n",
      "eval -0.31\n",
      "y_eval_hat 0.21\n",
      "FEN r1bqkbnr/5ppp/p1pp4/np2p3/4P3/1B3N2/PPPP1PPP/RNBQK2R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.36\n",
      "eval 0.00\n",
      "y_eval_hat -0.36\n",
      "FEN r2qkb1r/pp3ppp/n1p1pn2/3p4/3P1B2/2NbP3/PPP2PPP/R2QK1NR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 2.99\n",
      "eval 1.91\n",
      "y_eval_hat -1.08\n",
      "FEN rnbqkb1r/p1p1pppp/5n2/1B1p4/3P4/4PN2/PPP2PPP/RNBQK2R b KQkq -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 0.54\n",
      "eval -0.15\n",
      "y_eval_hat 0.39\n",
      "FEN r1bqkb1r/pp4pp/2n2n2/1Bpp4/8/5N2/PPP2PPP/RNBQK2R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1.27\n",
      "eval -1.27\n",
      "y_eval_hat -0.00\n",
      "FEN 3r4/7p/8/5p2/4k1N1/8/1B6/7K w - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.36\n",
      "eval -0.87\n",
      "y_eval_hat -0.51\n",
      "FEN r1bqkbnr/pp1p1ppp/2n5/4p3/3pP3/5NP1/PPP2P1P/RNBQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.23\n",
      "eval -0.36\n",
      "y_eval_hat -0.13\n",
      "FEN rn1qkbnr/pp3ppp/2p5/3ppb2/8/1PN1P3/PBPP1PPP/R2QKBNR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.06\n",
      "eval 0.25\n",
      "y_eval_hat 0.31\n",
      "FEN r2qkbnr/ppp1pppp/2np4/8/2PPP3/5b2/PP3PPP/RNBQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.47\n",
      "eval 0.49\n",
      "y_eval_hat 0.02\n",
      "FEN 8/4K3/8/6k1/6p1/3N2N1/8/8 w - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 201.74\n",
      "eval 200.00\n",
      "y_eval_hat -1.74\n",
      "FEN 8/8/2N5/3B4/5K2/3k4/8/8 b - -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 180.09\n",
      "eval 200.00\n",
      "y_eval_hat 19.91\n",
      "FEN 8/8/7R/8/1k2K3/R7/8/8 w - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.33\n",
      "eval 0.40\n",
      "y_eval_hat 0.07\n",
      "FEN rn1qkb1r/pp3ppp/2p1pn2/3p4/6b1/2NP1NP1/PPP1PPBP/R1BQK2R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 7.00\n",
      "eval -4.14\n",
      "y_eval_hat 2.86\n",
      "FEN r1bq1rk1/pppp1pp1/2n2n1B/2b1p3/2B1P3/2NP1N2/PPP2PPP/R2Q1RK1 b - -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 0.12\n",
      "eval 0.28\n",
      "y_eval_hat 0.16\n",
      "FEN rn1qk1nr/pbp2ppp/1p2p3/3p4/3PP3/2B2P2/PPP3PP/R2QKBNR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1.92\n",
      "eval 1.19\n",
      "y_eval_hat -0.73\n",
      "FEN r1bqk1nr/pppp1ppp/2n5/2b1p3/2B1P3/2P2N2/PP1P1PPP/RNBQ1RK1 b kq -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 3.52\n",
      "eval -1.42\n",
      "y_eval_hat 2.10\n",
      "FEN 5k1r/2n2p1p/2Q3p1/3n4/8/8/5PPP/6K1 b - -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 0.07\n",
      "eval 0.00\n",
      "y_eval_hat 0.07\n",
      "FEN rn1qkbnr/pp2pppp/2p5/3p4/3P2bN/2N5/PPP1PPPP/R1BQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1.51\n",
      "eval -0.97\n",
      "y_eval_hat 0.54\n",
      "FEN rnbqkbnr/ppp1pp1p/3p2p1/4P3/8/8/PPPPQPPP/RNB1KBNR b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1.93\n",
      "eval 0.98\n",
      "y_eval_hat -0.95\n",
      "FEN r1bqkbnr/2pp1pp1/p1n4p/1p2p3/4P3/1B1P1N2/PPP2PPP/RNBQ1RK1 b kq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.04\n",
      "eval 0.67\n",
      "y_eval_hat 0.63\n",
      "FEN r1bqk2r/pppnppbp/2n3p1/4P1B1/8/2N2N2/PPP2PPP/R2QKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.32\n",
      "eval -0.29\n",
      "y_eval_hat 0.03\n",
      "FEN rnbqkb1r/ppp1pppp/3p1n2/8/2P5/2N2P2/PP1PP1PP/R1BQKBNR b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 308.64\n",
      "eval 300.00\n",
      "y_eval_hat -8.64\n",
      "FEN 4R3/8/1k1K4/8/8/8/8/8 w - -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 0.42\n",
      "eval -0.20\n",
      "y_eval_hat 0.22\n",
      "FEN rnbqkb1r/pp3ppp/4pn2/3p4/2PP4/2N5/PP1B1PPP/R2QKBNR b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.02\n",
      "eval 0.00\n",
      "y_eval_hat -0.02\n",
      "FEN rnbq1rk1/ppp1ppbp/3p1np1/8/1P1P4/4PN2/P1P1BPPP/RNBQK2R w KQ -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.09\n",
      "eval -0.10\n",
      "y_eval_hat -0.01\n",
      "FEN r1bqkb1r/ppp2ppp/5n2/3p4/2PP4/8/PP3PPP/RNBQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.06\n",
      "eval -0.04\n",
      "y_eval_hat 0.02\n",
      "FEN 5rk1/7p/8/8/5p2/4N3/1B6/7K w - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1.23\n",
      "eval -1.11\n",
      "y_eval_hat 0.12\n",
      "FEN r1bqk2r/ppp2ppp/2p5/2b5/4P3/3Pn3/PPP1BPPP/RN1QK2R w KQkq -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 0.76\n",
      "eval -0.62\n",
      "y_eval_hat 0.14\n",
      "FEN rn1qkbnr/ppp2ppp/8/4P3/2p1P1b1/5N2/PP3PPP/RNBQKB1R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.72\n",
      "eval 0.21\n",
      "y_eval_hat -0.51\n",
      "FEN rnbqr1k1/pppp1ppp/4pn2/8/2PP4/2PBPN2/P4PPP/R1BQK2R b KQ -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1.42\n",
      "eval 0.75\n",
      "y_eval_hat -0.67\n",
      "FEN r1bqk1nr/ppp2pp1/2n1p2p/3p4/2PP4/4PNP1/PP3PP1/RN1QKB1R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.36\n",
      "eval 0.66\n",
      "y_eval_hat 0.30\n",
      "FEN rn1qkbnr/ppp2ppp/4b3/8/2pNP3/8/PP3PPP/RNBQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.03\n",
      "eval -0.21\n",
      "y_eval_hat -0.24\n",
      "FEN rnbqkbnr/ppp1pp1p/3p2p1/8/6P1/4P3/PPPP1P1P/RNBQKBNR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 2.37\n",
      "eval 1.47\n",
      "y_eval_hat -0.90\n",
      "FEN r1bqk1nr/ppp2ppp/2n5/3pP3/3P4/2P5/P4PPP/R1BQKBNR b KQkq -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 0.21\n",
      "eval 0.70\n",
      "y_eval_hat 0.91\n",
      "FEN rnb1kbnr/pp2pppp/2p5/3p4/3PPB2/2q2N2/P1PN1PPP/R2QKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 3.11\n",
      "eval 3.74\n",
      "y_eval_hat 0.63\n",
      "FEN rnbqkbr1/pppppppp/5n2/4P3/8/8/PPPP1PPP/RNBQKBNR w KQq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.26\n",
      "eval -0.37\n",
      "y_eval_hat -0.11\n",
      "FEN r3kbnr/1pp2ppp/p1p2q2/4p3/4P1b1/5N1P/PPPP1PP1/RNBQR1K1 b kq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1.20\n",
      "eval 0.87\n",
      "y_eval_hat -0.33\n",
      "FEN rnbq1rk1/ppp1ppbp/6p1/3p4/3PN2B/4PN2/PPP2PPP/R2QKB1R b KQ -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.06\n",
      "eval 0.98\n",
      "y_eval_hat 0.92\n",
      "FEN r1bqkbnr/p1p2ppp/1pn1p3/3p4/2PP4/P4N2/1P2PPPP/RNBQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.07\n",
      "eval 0.53\n",
      "y_eval_hat 0.46\n",
      "FEN r2qkbnr/ppp2ppp/2n1p3/3p4/2PP1B2/5P2/PP2PP1P/RN1QKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.13\n",
      "eval 0.10\n",
      "y_eval_hat -0.03\n",
      "FEN rnb1kb1r/p1pp1pp1/1p2pq1p/4P3/3P4/2P5/PP3PPP/RN1QKBNR b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.13\n",
      "eval -0.16\n",
      "y_eval_hat -0.03\n",
      "FEN rnbqk2r/pp1pbppp/2p2n2/4p3/2B1P3/2PP4/PP3PPP/RNBQK1NR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 843.09\n",
      "eval 850.00\n",
      "y_eval_hat 6.91\n",
      "FEN 8/8/8/8/4k3/4B3/8/4KB2 w - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.23\n",
      "eval -0.12\n",
      "y_eval_hat -0.35\n",
      "FEN rnbqk2r/pp1pnppp/4p3/8/1bB1P3/2N5/PP1B1PPP/R2QK1NR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.11\n",
      "eval -0.24\n",
      "y_eval_hat -0.35\n",
      "FEN r1bq1rk1/pppp1pp1/2n2n2/2b1p1p1/2B1P2P/3P4/PPP2PP1/RNBQK2R w KQ -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 2.70\n",
      "eval -8.68\n",
      "y_eval_hat -5.98\n",
      "FEN 3r1rk1/bp4q1/p1b1ppQ1/2P5/1P6/P7/5PPP/2R2RK1 w - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1.59\n",
      "eval 0.95\n",
      "y_eval_hat -0.64\n",
      "FEN rnbqkb1r/pp3ppp/4p1n1/3pP3/3P4/3B1N2/PP3PPP/RNBQK2R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.08\n",
      "eval 0.75\n",
      "y_eval_hat 0.83\n",
      "FEN rnb1kbnr/pp1p1ppp/2p5/q3p3/4P3/3P1N2/PPP2PPP/RNBQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.35\n",
      "eval -0.37\n",
      "y_eval_hat -0.02\n",
      "FEN rnbqkb1r/1pp2ppp/4pn2/p2p4/1P1P4/P4N2/2P1PPPP/RNBQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 11.47\n",
      "eval 8.01\n",
      "y_eval_hat -3.46\n",
      "FEN 2r2rk1/1b1q3B/p3p3/1p1p1pbQ/8/1P2P3/PBP2PPP/3R1RK1 b - -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 9.17\n",
      "eval 7.07\n",
      "y_eval_hat -2.10\n",
      "FEN 7Q/3k1r2/8/3K4/8/8/8/8 b - -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 0.24\n",
      "eval 0.69\n",
      "y_eval_hat 0.45\n",
      "FEN rnbqk1nr/p1pp1ppp/1p2p3/8/1b1P4/2N2N2/PPP1PPPP/R1BQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.21\n",
      "eval 0.00\n",
      "y_eval_hat 0.21\n",
      "FEN r1bq1rk1/pppp1ppp/3b1n2/1B2p3/3nP3/2N2N1P/PPPP1PP1/R1BQ1RK1 w - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1.03\n",
      "eval 0.54\n",
      "y_eval_hat -0.49\n",
      "FEN rn1qkbnr/pbpp1p1p/1p2p1p1/8/3P1B2/4PN2/PPPN1PPP/R2QKB1R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 3.82\n",
      "eval -1.71\n",
      "y_eval_hat 2.11\n",
      "FEN rnbq1rk1/ppp1pBbp/3p1np1/6N1/4P3/2N5/PPPP1PPP/R1BQK2R b KQ -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 2.64\n",
      "eval 1.82\n",
      "y_eval_hat -0.82\n",
      "FEN rnb1k1nr/ppp2ppp/8/2b1q3/8/2N2N2/PPPPB1PP/R1BQK2R b KQkq -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 0.44\n",
      "eval -0.54\n",
      "y_eval_hat -0.10\n",
      "FEN r1bqk2r/1ppp1ppp/p1n2n2/2b5/4P3/2N5/PPP2PPP/RNBQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.22\n",
      "eval 1.87\n",
      "y_eval_hat 1.65\n",
      "FEN rn2kbnr/ppp2ppp/4bq2/4N3/2BPp3/8/PPP2PPP/RNBQK2R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.39\n",
      "eval 0.21\n",
      "y_eval_hat -0.18\n",
      "FEN r1bqkbnr/1p3ppp/p1npp3/2p5/P2PPP2/2N2N2/1PP3PP/R1BQKB1R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.69\n",
      "eval -0.27\n",
      "y_eval_hat 0.42\n",
      "FEN r1bqk2r/pp1p1ppp/2n1pn2/6B1/1bP5/2N2N2/PP1QPPPP/R3KB1R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.98\n",
      "eval -0.97\n",
      "y_eval_hat 0.01\n",
      "FEN rnbqk2r/pp2bppp/2pp1n2/5NB1/4P3/2N5/PPP2PPP/R2QKB1R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 34.75\n",
      "eval -20.18\n",
      "y_eval_hat 14.57\n",
      "FEN 6k1/6pp/4p3/2qp1Q2/1p3P2/1P2P3/P5PP/6K1 b - -\n",
      "Accuracy% = 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Eval 1.36\n",
      "eval 1.48\n",
      "y_eval_hat 0.12\n",
      "FEN 1rbq1rk1/3nbppp/p1n1p3/1p1pP3/2pP1P2/P1N1BN2/1PPQB1PP/R4RK1 w - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 2.12\n",
      "eval -1.11\n",
      "y_eval_hat 1.01\n",
      "FEN rnbqkb1r/pp1ppppp/5n2/8/2B1P3/2N5/PB3PPP/R2QK1NR b KQkq -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 1.26\n",
      "eval 0.56\n",
      "y_eval_hat -0.70\n",
      "FEN rnbqkbnr/pp4pp/4pp2/3p4/3P1B2/4PN2/PP3PPP/RN1QKB1R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.20\n",
      "eval 0.33\n",
      "y_eval_hat 0.13\n",
      "FEN rnbqkb1r/ppp2ppp/3p1n2/8/3Q4/1P6/PBP1PPPP/RN2KBNR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.25\n",
      "eval 0.30\n",
      "y_eval_hat 0.05\n",
      "FEN rnbqk2r/ppp1bppp/3p1n2/4p3/8/1PN1P3/PBPP1PPP/R2QKBNR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.84\n",
      "eval 0.85\n",
      "y_eval_hat 0.01\n",
      "FEN rnbqk1nr/pppp1ppp/4p3/2b5/4P2P/8/PPPP1PP1/RNBQKBNR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.34\n",
      "eval -0.21\n",
      "y_eval_hat 0.13\n",
      "FEN rn1qkb1r/pp3ppp/2p1pn2/3P1b2/3P4/2N1P2P/PP3PP1/R1BQKBNR b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.09\n",
      "eval 0.20\n",
      "y_eval_hat 0.29\n",
      "FEN r1bqk2r/pp1pbppp/2n1pn2/2p3B1/3P4/4PN2/PPPN1PPP/R2QKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 630.10\n",
      "eval 650.00\n",
      "y_eval_hat 19.90\n",
      "FEN 8/8/3N4/B7/8/4K3/1k6/8 b - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.68\n",
      "eval 0.52\n",
      "y_eval_hat -0.16\n",
      "FEN rnbqkb1r/pp2pppp/2pp1n2/8/2P1P3/6P1/PP1P1PBP/RNBQK1NR b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1.03\n",
      "eval -0.49\n",
      "y_eval_hat 0.54\n",
      "FEN rn1qkb1r/pbpp1ppp/1p2pn2/8/2B1P3/P2P3P/1PP2PP1/RNBQK1NR b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.01\n",
      "eval -0.18\n",
      "y_eval_hat -0.19\n",
      "FEN r1bqkbnr/pppnpppp/8/3p4/3P1P2/8/PPP1P1PP/RNBQKBNR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 47.50\n",
      "eval 49.56\n",
      "y_eval_hat 2.06\n",
      "FEN 8/8/8/8/3k1NK1/1B6/8/8 w - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.04\n",
      "eval 0.93\n",
      "y_eval_hat 0.97\n",
      "FEN r1bq1rk1/pppn1ppp/4pn2/b2pN3/3P1B2/2P1P3/PP1N1PPP/R2QKB1R w KQ -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.06\n",
      "eval 0.06\n",
      "y_eval_hat 0.00\n",
      "FEN r1bqk2r/ppp2ppp/1bnp1n2/4p3/2B1P3/P2P1N1P/1PP2PP1/RNBQK2R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.11\n",
      "eval 0.59\n",
      "y_eval_hat 0.70\n",
      "FEN rn1qk2r/pbp2ppp/1p1ppn2/8/1b1PP3/2NB1P2/PPPB2PP/R2QK1NR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.71\n",
      "eval -0.50\n",
      "y_eval_hat 0.21\n",
      "FEN r1bqk2r/ppp2ppp/2n2n2/2bpp3/4P3/2PP1NP1/PP1N1PBP/R1BQK2R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.26\n",
      "eval 0.98\n",
      "y_eval_hat 0.72\n",
      "FEN r1bqkbnr/pp1np1pp/2p5/3pN3/5P2/8/PPPP2PP/RNBQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.04\n",
      "eval -0.03\n",
      "y_eval_hat 0.01\n",
      "FEN rnbqk2r/pp3ppp/2pp1n2/2b1p3/4P3/2NP1N2/PPP1BPPP/R1BQ1RK1 b kq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 430.10\n",
      "eval 450.00\n",
      "y_eval_hat 19.90\n",
      "FEN 8/2kN1p2/R7/4P3/8/8/8/6K1 w - -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.81\n",
      "eval -1.00\n",
      "y_eval_hat -0.19\n",
      "FEN r1b1kbnr/pp3ppp/1qn1p3/3pP3/3p4/P1P5/1P1N1PPP/R1BQKBNR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 9.18\n",
      "eval 5.44\n",
      "y_eval_hat -3.74\n",
      "FEN rnb2bnr/ppp1p1kp/6P1/3B4/8/8/PPPP1PPP/RNB1K1NR b KQ -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 1.63\n",
      "eval 0.78\n",
      "y_eval_hat -0.85\n",
      "FEN rn1qkb1r/p3ppp1/1pp2n1p/3p1b2/2PP1B2/1QN1PN2/PP3PPP/R3KB1R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.22\n",
      "eval 0.88\n",
      "y_eval_hat 0.66\n",
      "FEN rnbqkbnr/1p1p1ppp/2p1p3/p7/2P5/6P1/PP1PPPBP/RNBQK1NR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.28\n",
      "eval 0.41\n",
      "y_eval_hat 0.13\n",
      "FEN r1bqr1k1/pppp1ppp/2nb4/1B2p3/4P1n1/P1NP1N2/1PP2P1P/R1BQK2R w KQ -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 1.79\n",
      "eval 0.94\n",
      "y_eval_hat -0.85\n",
      "FEN r1b1kbnr/pppp1ppp/5q2/8/4P3/2N2P2/PPP2P1P/R1BQKB1R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.42\n",
      "eval 0.02\n",
      "y_eval_hat -0.40\n",
      "FEN r2qkb1r/p1p2ppp/1pn1pn2/1Q1p1b2/2PP1B2/4PN2/PP3PPP/RN2KB1R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 319.79\n",
      "eval 300.00\n",
      "y_eval_hat -19.79\n",
      "FEN 8/6k1/2KQ4/8/8/8/8/8 w - -\n",
      "Accuracy% = 0.01\n",
      "Loss Eval 1.03\n",
      "eval 0.62\n",
      "y_eval_hat -0.41\n",
      "FEN rn1qk1nr/1bppppb1/pp4pp/8/3P1B2/2PBPN2/PP1N1PPP/R2QK2R b KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.77\n",
      "eval 0.97\n",
      "y_eval_hat 0.20\n",
      "FEN r1b1kb1r/pp1ppppp/2n2n2/q1p5/3P1B2/2P1P3/PP3PPP/RN1QKBNR w KQkq -\n",
      "Accuracy% = 0.0\n",
      "Loss Eval 0.55\n",
      "eval 0.00\n",
      "y_eval_hat 0.55\n",
      "FEN r1b1kb1r/pppp1p1p/5q2/8/3nPp1P/2N5/PPPP2P1/R1BQKB1R w KQkq -\n",
      "Accuracy% = 0.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, SVG\n",
    "import random\n",
    "\n",
    "SVG_BASE_URL = \"https://us-central1-spearsx.cloudfunctions.net/chesspic-fen-image/\"\n",
    "\n",
    "def svg_url(fen):\n",
    "  fen_board = fen.split()[0]\n",
    "  return SVG_BASE_URL + fen_board\n",
    "\n",
    "def show_index(idx):\n",
    "  count = 0\n",
    "  dataset =[]\n",
    "  evals=[]\n",
    "  with open('lichess_db_eval.jsonl', 'r') as file:\n",
    "      for i in range(idx+1):\n",
    "          line = file.readline()\n",
    "          if not line:\n",
    "              break\n",
    "      json_object = json.loads(line)\n",
    "      dataset.append(json_object)\n",
    "\n",
    "  fen = dataset[0]['fen']\n",
    "  pv = dataset[0]['evals'][0]['pvs'][0]\n",
    "  if (('cp' in pv and pv['cp'] is None) or ('cp' not in pv)):\n",
    "      eval = 5000*pv['mate']\n",
    "  else:\n",
    "      eval = dataset[0]['evals'][0]['pvs'][0]['cp']\n",
    "\n",
    "  x = torch.tensor(fen_to_features(fen))\n",
    "  eval = torch.tensor([eval], dtype=torch.float32)/100\n",
    "  y_hat_eval= model(x).squeeze()\n",
    "  loss_eval = F.l1_loss(y_hat_eval.unsqueeze(0), eval)\n",
    "  loss_eval_per = (loss_eval/eval)*100\n",
    "  print(f'Loss Eval {loss_eval:.2f}')\n",
    "#   print(f'LossEval% {loss_eval_per.item():.2f}%')\n",
    "  print(f'eval {eval.item():.2f}')\n",
    "  print(f'y_eval_hat {y_hat_eval:.2f}')\n",
    "  print(f'FEN {fen}')\n",
    "  if not(y_hat_eval > -1 and y_hat_eval < 1 and eval > -1 and eval < 1) and y_hat_eval*eval < 0 :\n",
    "    count = count+1\n",
    "  return count\n",
    "#   display(SVG(url=svg_url(fen)))\n",
    "\n",
    "for i in range(100):\n",
    "  idx = random.randint(1000000, 1500000)\n",
    "  count_wrong_pred = show_index(idx)/100\n",
    "  print(f'Accuracy% = {count_wrong_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4437866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save('model_is_it_magnoos_level.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dd888dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'scripted.pt'\n",
    "model_scripted = torch.jit.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33928624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy% = 100.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, SVG\n",
    "import random\n",
    "\n",
    "SVG_BASE_URL = \"https://us-central1-spearsx.cloudfunctions.net/chesspic-fen-image/\"\n",
    "\n",
    "def svg_url(fen):\n",
    "  fen_board = fen.split()[0]\n",
    "  return SVG_BASE_URL + fen_board\n",
    "\n",
    "def show_index(idx):\n",
    "  count = 0\n",
    "  dataset =[]\n",
    "  evals=[]\n",
    "  with open('lichess_db_eval.jsonl', 'r') as file:\n",
    "      for i in range(idx+1):\n",
    "          line = file.readline()\n",
    "          if not line:\n",
    "              break\n",
    "      json_object = json.loads(line)\n",
    "      dataset.append(json_object)\n",
    "\n",
    "  fen = dataset[0]['fen']\n",
    "  pv = dataset[0]['evals'][0]['pvs'][0]\n",
    "  if (('cp' in pv and pv['cp'] is None) or ('cp' not in pv)):\n",
    "      eval = 5000*pv['mate']\n",
    "  else:\n",
    "      eval = dataset[0]['evals'][0]['pvs'][0]['cp']\n",
    "\n",
    "  x = torch.tensor(fen_to_features(fen))\n",
    "  eval = torch.tensor([eval], dtype=torch.float32)/100\n",
    "  y_hat_eval= model_scripted(x).squeeze()\n",
    "  loss_eval = F.l1_loss(y_hat_eval.unsqueeze(0), eval)\n",
    "  loss_eval_per = (loss_eval/eval)*100\n",
    "#   print(f'Loss Eval {loss_eval:.2f}')\n",
    "#   print(f'LossEval% {loss_eval_per.item():.2f}%')\n",
    "#   print(f'eval {eval.item():.2f}')\n",
    "#   print(f'y_eval_hat {y_hat_eval:.2f}')\n",
    "#   print(f'FEN {fen}')\n",
    "  if not(y_hat_eval > -1 and y_hat_eval < 1 and eval > -1 and eval < 1) and y_hat_eval*eval < 0 :\n",
    "    count = count+1\n",
    "  return count\n",
    "#   display(SVG(url=svg_url(fen)))\n",
    "count_wrong_pred = 0\n",
    "max_count = 10\n",
    "for i in range(max_count):\n",
    "  idx = random.randint(5072000, 5472000)\n",
    "  count_wrong_pred += show_index(idx)\n",
    "#   print(count_wrong_pred)\n",
    "print(f'Accuracy% = {((max_count - count_wrong_pred)/max_count)*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ecc6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
